{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier, AdaBoostClassifier\n",
    "from bs4 import BeautifulSoup\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "import sys \n",
    "from textblob import TextBlob, Word\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.utils import resample\n",
    "from sklearn.multioutput import ClassifierChain\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "pd.set_option('display.max_rows', 100) # to look at more rows of data later\n",
    "pd.set_option('display.max_columns', 100) # to expand columns view so that all can be seen later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../dataset/positiveset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['severe_toxicity','obscene','threat','insult','identity_attack','sexual_explicit']\n",
    "for i in col:\n",
    "    data[i] = [1 if i >= 0.5 else 0 for i in data[i]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['comment'],\n",
    "                                                    data[col],\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=42,\n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "    'cvec': CountVectorizer(),\n",
    "    'tvec': TfidfVectorizer(),\n",
    "    'lr': LogisticRegression(solver='lbfgs'),\n",
    "    'knn': KNeighborsClassifier(),\n",
    "    'nb': MultinomialNB(),\n",
    "    'rf': RandomForestClassifier(),\n",
    "    'et': ExtraTreesClassifier(),\n",
    "    'ada': AdaBoostClassifier(random_state=42),\n",
    "    'ovr_lr': OneVsRestClassifier(LogisticRegression(solver='lbfgs',max_iter=300)),\n",
    "    'clf_lr': ClassifierChain(LogisticRegression(solver='lbfgs',max_iter=300),random_state=42,order='random'),\n",
    "    'clf_ada': ClassifierChain(AdaBoostClassifier())\n",
    "}\n",
    "\n",
    "model_full = {\n",
    "    'cvec': 'CountVectorizer',\n",
    "    'tvec': 'TfidfVectorizer',\n",
    "    'lr': 'Logistic Regression',\n",
    "    'knn': 'KNearestNeighbor',\n",
    "    'nb': 'Multinomial NB',\n",
    "    'dt': 'Decision Tree',\n",
    "    'rf': 'Random Forest',\n",
    "    'et': 'Extra Tree',\n",
    "    'ada': 'AdaBoost',\n",
    "    'ovr_lr': 'OneVsRest (Logistic Regression)',\n",
    "    'clf_lr': 'Classifier Chain (Logistic Regression)',\n",
    "    'clf_ada': 'Classifier Chain (Adaboost)'\n",
    "}\n",
    "\n",
    "param_dict = {\n",
    "    'cvec': {\n",
    "        'cvec__max_features': [5000,6000,7000],\n",
    "        'cvec__min_df': [3,4],\n",
    "        'cvec__max_df': [.9, .95],\n",
    "        'cvec__ngram_range': [(1,1), (1,2)]\n",
    "    },\n",
    "    'tvec': {\n",
    "        'tvec__max_features': [5000,6000,7000],\n",
    "        'tvec__min_df': [3,4],\n",
    "        'tvec__max_df': [.9, .95],\n",
    "        'tvec__ngram_range': [(1,1), (1,2)]\n",
    "    },\n",
    "    'knn': {\n",
    "        'knn__n_neighbors': [5,6,7,8,9]\n",
    "    },\n",
    "    'lr': {},\n",
    "    'nb': {},\n",
    "    'dt': {\n",
    "        'dt__max_depth': [5,7],\n",
    "        'dt__min_samples_split': [10,15],\n",
    "        'dt__min_samples_leaf': [3,4]\n",
    "    },\n",
    "    'rf': {\n",
    "        'rf__n_estimators': [100],\n",
    "        'rf__max_depth': [5,7],\n",
    "        'rf__min_samples_split': [10,15],\n",
    "        'rf__min_samples_leaf': [3,4]\n",
    "        \n",
    "    },\n",
    "    'et': {\n",
    "        'et__n_estimators': [100],\n",
    "        'et__max_depth': [5,7],\n",
    "        'et__min_samples_split': [10,15],\n",
    "        'et__min_samples_leaf': [3,4]\n",
    "    },\n",
    "    'ada': {\n",
    "        'ada__n_estimators': [50,100,200],\n",
    "        'ada__learning_rate': [0.9, 1]\n",
    "    },\n",
    "    'ovr_lr': {},\n",
    "    'clf_lr': {},\n",
    "    'clf_ada': {}\n",
    "}\n",
    "\n",
    "def prepare_pipeline(list_of_models):\n",
    "    \"\"\"\n",
    "    Prepare pipeline of models to be used for modelling\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    list_of_models: list[str]\n",
    "        List of models to be included for pipeline\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Pipeline\n",
    "        Pipeline of models to be run\n",
    "    \"\"\"\n",
    "    pipe_list = [(i,model_dict[i]) for i in list_of_models]\n",
    "    return Pipeline(pipe_list)\n",
    "\n",
    "def add_params(name,pipe_dict):\n",
    "    \"\"\"\n",
    "    Add parameters for GridSearch\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    name: str\n",
    "        Name of model/vectorization method to have params added.\n",
    "    pipe_dict: Dictionary\n",
    "        Dictionary that contains parameters to be added into GridSearch\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Dictionary\n",
    "        Dictionary that contains parameters to be added for GridSearch\n",
    "    \"\"\"\n",
    "    params = param_dict[name]\n",
    "    for k,v in params.items():\n",
    "        pipe_dict[k] = v\n",
    "    return pipe_dict\n",
    "\n",
    "def grid_search(vec_method,model,filename,X_train=X_train,y_train=y_train,X_test=X_test,y_test=y_test):\n",
    "    \"\"\"\n",
    "    Initialize and run GridSearch\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    vec_method: str\n",
    "        Vectorization method to use. Vectorization method has to be contained in model_dict.\n",
    "        \n",
    "    model: str\n",
    "        Initialize which classification model to use. Note classification model has to be contained in model_dict.\n",
    "        \n",
    "    filename: str\n",
    "        Name of pickle file to save to.\n",
    "        \n",
    "    X_train: list[str]\n",
    "        List of training data to be used\n",
    "        \n",
    "    y_train: list[str]\n",
    "        Target value of the training data\n",
    "        \n",
    "    X_test: list[str]\n",
    "        List of test data to be used \n",
    "        \n",
    "    y_test: list[str]\n",
    "        Target value of test data\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    List\n",
    "        List that contains predicted values of the test data\n",
    "    \"\"\"\n",
    "    pipe_params = {}\n",
    "    pipe_params = add_params(vec_method,pipe_params)\n",
    "    pipe_params = add_params(model,pipe_params)\n",
    "    pipe = prepare_pipeline([vec_method,model])\n",
    "    gs = GridSearchCV(pipe,param_grid=pipe_params,cv=3,n_jobs=3)\n",
    "    gs.fit(X_train,y_train)\n",
    "    print(f'Using {model_full[model]} with {model_full[vec_method]}:')\n",
    "    print(f'Train Score: {round(gs.best_score_,4)}')\n",
    "    print(f'Test Score: {round(gs.score(X_test,y_test),4)}')\n",
    "    print(f'Using the following parameters: {gs.best_params_}')\n",
    "    # Save model into pickle\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    return gs.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using OneVsRest (Logistic Regression) with CountVectorizer:\n",
      "Train Score: 0.7048\n",
      "Test Score: 0.7109\n",
      "Using the following parameters: {'cvec__max_df': 0.9, 'cvec__max_features': 5000, 'cvec__min_df': 4, 'cvec__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "ovrlr_cvec_predictions = grid_search('cvec','ovr_lr','cvec_ovrlr.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using OneVsRest (Logistic Regression) with TfidfVectorizer:\n",
      "Train Score: 0.722\n",
      "Test Score: 0.7276\n",
      "Using the following parameters: {'tvec__max_df': 0.9, 'tvec__max_features': 6000, 'tvec__min_df': 3, 'tvec__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "ovrlr_tvec_predictions = grid_search('tvec','ovr_lr','tvec_ovrlr.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Classifier Chain (Logistic Regression) with CountVectorizer:\n",
      "Train Score: 0.7061\n",
      "Test Score: 0.7128\n",
      "Using the following parameters: {'cvec__max_df': 0.9, 'cvec__max_features': 5000, 'cvec__min_df': 3, 'cvec__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "clflr_cvec_predictions = grid_search('cvec','clf_lr','cvec_clflr.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Classifier Chain (Logistic Regression) with TfidfVectorizer:\n",
      "Train Score: 0.7191\n",
      "Test Score: 0.7254\n",
      "Using the following parameters: {'tvec__max_df': 0.9, 'tvec__max_features': 5000, 'tvec__min_df': 4, 'tvec__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "clflr_tvec_predictions = grid_search('tvec','clf_lr','tvec_clflr.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Classifier Chain (Adaboost) with TfidfVectorizer:\n",
      "Train Score: 0.7034\n",
      "Test Score: 0.7068\n",
      "Using the following parameters: {'tvec__max_df': 0.9, 'tvec__max_features': 6000, 'tvec__min_df': 3, 'tvec__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "clfada_tvec_predictions = grid_search('tvec','clf_ada','tvec_clfada.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Classifier Chain (Adaboost) with CountVectorizer:\n",
      "Train Score: 0.6931\n",
      "Test Score: 0.6977\n",
      "Using the following parameters: {'cvec__max_df': 0.9, 'cvec__max_features': 5000, 'cvec__min_df': 3, 'cvec__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "clfada_cvec_predictions = grid_search('cvec','clf_ada','cvec_clfada.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
